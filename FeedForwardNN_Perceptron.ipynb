{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we describe the very first model of feedforward Neural Network, the Perceptron. The structure of the notebook is then:\n",
    "\n",
    "- [Theoretical Analysis](#s1)\n",
    "    - [Algorithm](#s1.1)\n",
    "    - [Practical Tips](#s1.2)\n",
    "- [Implementation in Python](#s2)\n",
    "- [Mini-challenge](#s3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a class=\"anchor\" id='s1'> Theoretical Analysis </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of machine learning, the __Perceptron__ is an algorithm for supervised learning of binary classifiers. We remind that a binary classifier is a function which can decide whether or not an input, represented by a vector of numbers, belongs to some specific class. It is a type of linear classifier, i.e. a classification algorithm that makes its predictions based on a linear predictor function combining a set of weights with the feature vector. In more geometrical terms, a linear classsifier is a model that is able to divide the two classes in the input vector space of features, with an hyperplane. \n",
    "\n",
    "In the context of Neural Network , the Perceptron is the simplest feedforward Neural Network and does not contain any hidden layer, which means it only consists of a single layer of output nodes. \n",
    "\n",
    "Historically, the very first step towards the perceptron, and in general towards the artificial neuron, was taken by Warren McCulloch and Walter Pitts in 1943 inspired by neurobiology, created a model known as McCulloch-Pitts Neuron. \n",
    "In the MP Neuron Model, all the inputs have the same weight while calculating the outcome and the bias parameter can only take fewer values i.e., the parameter space for finding the best parameter is limited.\n",
    "In 1958 Frank Rosenblatt proposed the Perceptron, a more generalized computational model than the McCulloch-Pitts Neuron. The important feature in the Rosenblatt proposed perceptron was the introduction of weights for the inputs.\n",
    "\n",
    "Thus, the basic artificial perceptron we are going to describe can be represented by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img width=500 src='images/perc.png' /> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <a class=\"anchor\" id='s1.1'> Algorithm </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we already said the perceptron is the simplest type of feedforward neural network, i.e. a feedforward NN with no hidden layers or units. Thus, a perceptron has only an input layer and an output layer. In order to describe and define the neural net and its algrithm, we have define, beyond the number of layers and the type of net, the activation functions used and the loss function. Historically, the perceptron's output has been binary, meaning it outputs a value of $0$ or $1$. We therefore recall some definition in order to be more formal and clear:\n",
    "\n",
    "\\begin{align*}\n",
    "x_i&:\\quad\\text{$i$-th $(p+1)$-dimensional training input vector}\\,\\left(1,x_{1i},\\cdots, x_{pi}\\right)\\\\\n",
    "y_i&:\\quad\\text{$i$-th training output vector}\\\\\n",
    "w&:\\quad\\text{$(p+1)$-dimensional weight vector}\\,\\left(w_0,w_{1},\\cdots, w_{p}\\right)\\\\\n",
    "o_i&:\\quad\\text{perceptron $i$-th output value}\n",
    "\\end{align*}\n",
    "\n",
    "The activation function we will use is the binary step function, defined as\n",
    "\n",
    "\\begin{align*}\n",
    "H(z)=\\begin{cases} 0, &  z<0 \\\\ 1, & z\\geq 0\\end{cases}\n",
    "\\end{align*}\n",
    "\n",
    "More generally, a perceptron can use other activation functions, like the sigmoid or linear functions. The loss function we will use the cross entropy loss\n",
    "\n",
    "\\begin{align*}\n",
    "L(y_i,\\hat{y}_i)=-y_i\\log\\hat{y}_i-(1-y_i)\\log(1-\\hat{y}_i)\n",
    "\\end{align*}\n",
    "\n",
    "The learning algorithm is simple and it goes as follows. For each observation the perceptron take as input the input value $x_i$ and it weights them with $w_i$. Then it passes this scalar $z_i$ through the activation function $H(z_i)$ that produces the output $o_i$. Then we the perceptron outputs are compared to the desired output $y_i$ thanks to the loss function $L$. Once the cost function has been computed we have to find the optimal $w$ in order to minimize the risk function $\\mathcal{R}$. The step described so far can be summarized as\n",
    "\n",
    "0. Randomly inizialize $w$\n",
    "1. $z_i=w_i\\cdot x_i$\n",
    "2. $o_i=H(z_i)$\n",
    "3. $L(y_i,o_i)=-y_i\\log o_i-(1-y_i)\\log(1-o_i)$\n",
    "4. $\\mathcal{R}(w)=\\sum_{i=1}^N L(y_i,H(w_i\\cdot x_i))$\n",
    "\n",
    "where we have shown the explicitly the dependance of $\\mathcal{R}(w)$ on the weights $w$ through the activation function. $\\mathcal{R}(w)$ is tipically minimized using gradient descents, meaning the perceptron adjust $w$ in the direction of the negative gradient of the risk function, in order to minimize it. This iterative process reduces the value of the error function until it converges on a value, usually a local minimum. The values of the weights $w$ are inizialized randomly as shown in the point 1 of the pseudo code above, and then are update according to the equation\n",
    "\n",
    "\\begin{align*}\n",
    "w_{n+1}=w_n-\\eta\\left .\\frac{\\partial\\mathcal{R}(w)}{\\partial w}\\right |_{w=w_n}\n",
    "\\end{align*}\n",
    "\n",
    "where $w_n$ are the values of $w$ after the $n$-th iteration, and $\\eta$ is the learning rate which controls the step size gradient descent takes each iteration, typically chosen to be a small value. After we update the weight we repeat the steps 0-4 and we reupdate  the weights and so on until we reach the number of __Epochs__ (iterations) we set a priori. \n",
    "\n",
    "The weight delta is calculate using the __delta rule__ that is a special case of __backpropagation__ that we explain in the introductionary notebook to Neural Networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <a class=\"anchor\" id='s1.2'> Practical Tips </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was mentioned earlier that single-layer perceptrons are linear classifiers. That is, they can only learn linearly separable patterns. Linearly separable patterns are datasets or functions that can be separated by a linear boundary (a line or hyperplane). It has been shown, for example, that it was impossible for a perceptron to learn even simple non-linearly separable functions such as the [XOR function](https://en.wikipedia.org/wiki/XOR_gate#Analytical_representation). Many other (indeed, most other) functions are not linearly separable, so what is needed is an extension to the perceptron. The obvious extension is to add more layers of units so that there are nonlinear computations in between the input and output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a class=\"anchor\" id='s2'> Implementation in Python </a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classe `Perceptron` of the module `sklearn.linear_model` are:\n",
    "\n",
    "`Perceptron(penalty=None, alpha=0.0001, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False)`\n",
    "\n",
    "\n",
    "Since it's a class is composed by __parameters__, __attributes__ and __method__. The official page where all the details can be found is [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html#sklearn.linear_model.Perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <a class=\"anchor\" id='s3'> Mini-Challenge </a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import Perceptron \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('data/heart.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>168</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "      <td>220</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>152</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>184</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>309</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  \\\n",
       "116   41    1   2       130   214    0        0      168      0      2.0   \n",
       "154   39    0   2       138   220    0        1      152      0      0.0   \n",
       "78    52    1   1       128   205    1        1      184      0      0.0   \n",
       "301   57    1   0       130   131    0        1      115      1      1.2   \n",
       "61    54    1   1       108   309    0        1      156      0      0.0   \n",
       "\n",
       "     slope  ca  thal  target  \n",
       "116      1   0     2       1  \n",
       "154      1   0     2       1  \n",
       "78       2   0     2       1  \n",
       "301      1   1     3       0  \n",
       "61       2   0     3       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df.drop('target',axis=1), df.target, shuffle=True, train_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a21334f98>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=Perceptron()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_test, model.predict(X_test)), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the SVC is 0.6721311475409836\n"
     ]
    }
   ],
   "source": [
    "print('The accuracy of the SVC is',accuracy_score(y_test, model.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
